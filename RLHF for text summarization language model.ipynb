{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LV4-CQQSsU6S"
      },
      "source": [
        "MODEL LINK : https://huggingface.co/bigcode/tiny_starcoder_py\n",
        "\n",
        "DATASET FOR STEP 2: https://huggingface.co/datasets/CarperAI/openai_summarize_comparisons\n",
        "\n",
        "DATASET FOR STEP 1 and 3: https://huggingface.co/datasets/CarperAI/openai_summarize_tldr"
      ],
      "id": "LV4-CQQSsU6S"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92tjUDCAiTyC",
        "outputId": "7145c405-3572-4d69-e016-5294a416887b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "92tjUDCAiTyC"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2fa80b0e"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    default_data_collator,\n",
        ")\n",
        "\n",
        "\n",
        "def set_seed(seed_val=42):\n",
        "    random.seed(seed_val)\n",
        "    np.random.seed(seed_val)\n",
        "    torch.manual_seed(seed_val)\n",
        "    torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "\n",
        "train_batch_size = 16\n",
        "gradient_accumulation_steps = 1\n",
        "learning_rate = 1e-5\n",
        "eval_batch_size = 1\n",
        "eval_steps = 500\n",
        "max_input_length = 550\n",
        "save_steps = 1000\n",
        "num_train_epochs = 20\n",
        "random.seed(42)\n",
        "\n",
        "\n"
      ],
      "id": "2fa80b0e"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "W2endTf3kcaa"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/drive/My Drive/test.parquet'"
      ],
      "id": "W2endTf3kcaa"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "z98_XfO7mFPz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f0a1154-d7ec-431d-b098-3605da4cf16b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 108781\n",
            "-rw------- 1 root root      190 Dec 19 00:12  1CatA2d3QAqmrQNndzAKQg_420b4adfcdec47a0b0c67d6c5cea0641_Cosmetics-Inc..gsheet\n",
            "-rw------- 1 root root     9463 Dec 19 00:04  1CatA2d3QAqmrQNndzAKQg_420b4adfcdec47a0b0c67d6c5cea0641_Cosmetics-Inc..xlsx\n",
            "-rw------- 1 root root      190 Jul  1  2023 'Bakery sales july 2023.gsheet'\n",
            "drwx------ 2 root root     4096 Feb  2  2023 'Colab Notebooks'\n",
            "-rw------- 1 root root      214 Nov 29 01:03 'Converting numerical and text values - Preparing for VLOOKUP.gsheet'\n",
            "-rw------- 1 root root      190 Feb  4 12:39 'Copy of Calla & Ivy Content Calendar and Audit for Quiz.gsheet'\n",
            "-rw------- 1 root root      190 Jan 26 00:59 'Copy of Create a Facebook Business Page or an Instagram Business Account - Templates.gslides'\n",
            "-rw------- 1 root root      190 Feb 11 02:22 'Copy of Create an Ad Templates  - Template.gslides'\n",
            "-rw------- 1 root root      190 Feb 11 02:14 'Copy of Create the Creative Brief for your Paid-Ad - Project Template.gslides'\n",
            "-rw------- 1 root root      190 Jul  5  2023 'Copy of Formulas for Google Sheets Draft.gsheet'\n",
            "-rw------- 1 root root      214 Nov  1 12:14 'Cosmetics Inc. - Data for Pivot Table and VLOOKUP.gsheet'\n",
            "-rw------- 1 root root      190 Jan 21 02:24 'Create a Customer Persona and Journey.gslides'\n",
            "-rw------- 1 root root      214 Dec 19 00:03  Customer-service-survey-responses.gsheet\n",
            "-rw------- 1 root root      214 Oct 31 00:07  CustomerSurveyData.gsheet\n",
            "-rw------- 1 root root      190 Jul 14  2023  CustomerSurvey.gsheet\n",
            "-rw------- 1 root root      190 Nov  1 00:48 'Data Spreadsheet for \"Cleaning with Spreadsheets\" .gsheet'\n",
            "-rw------- 1 root root      214 Oct 31 00:08 'DeliveryTimes DistanceData.gsheet'\n",
            "-rw------- 1 root root 84626505 Feb  8  2023  drugsComTrain.csv\n",
            "-rw------- 1 root root      214 Dec  1 10:08 'Dynamic Dataset.gsheet'\n",
            "-rw------- 1 root root      190 Oct 16 12:43 'Example Spreadsheet - Entertainment Expenses .gsheet'\n",
            "-rw------- 1 root root      190 Jul 14  2023  HistoricalSales.gsheet\n",
            "-rw------- 1 root root      190 Nov  1 06:07 'International Logistics Association Memberships - Data for Cleaning.gsheet'\n",
            "-rw------- 1 root root      190 Nov  1 00:26 'International Logistics Association Memberships - Data to Merge.gsheet'\n",
            "-rw------- 1 root root      190 Dec 22 23:23  Learning-Log-Template_Review-a-slide-presentation.gdoc\n",
            "-rw------- 1 root root      190 Dec  6 23:45 'Making your own visualization - example dataset.gsheet'\n",
            "-rw------- 1 root root      190 Jul  6  2023 'Monthly Sales - Functions 101.gsheet'\n",
            "-rw------- 1 root root      214 Jul  5  2023 'Monthly Sales.gsheet'\n",
            "-rw------- 1 root root      214 Nov 30 01:00 'Movie Data Starter Project (1).gsheet'\n",
            "-rw------- 1 root root      214 Nov 30 01:29 'Movie Data Starter Project.gsheet'\n",
            "-rw------- 1 root root      190 Jul 14  2023  PatelEventsData.gsheet\n",
            "-rw------- 1 root root    62079 Jul  1  2023  Population-Latin-and-Caribbean-Countries-2010-2019.xlsx\n",
            "-rw------- 1 root root      190 Dec 22 23:21 'Positive and negative trends in annual sales.gslides'\n",
            "-rw------- 1 root root      190 Oct 27 06:03 'Sales Rep Cities, States, and Parts.gsheet'\n",
            "-rw------- 1 root root      214 Jul  7  2023 'Scope-Of-Work Template.gdoc'\n",
            "-rw------- 1 root root      190 Jul  5  2023 'Spreadsheet Errors and Fixes Demo Sheets.gsheet'\n",
            "-rw------- 1 root root 20441979 Mar 25 16:42  test2.parquet\n",
            "-rw------- 1 root root  6225522 Mar 25 16:41  test.parquet\n",
            "-rw------- 1 root root      190 Feb  3 01:16 'Three-Month Content Calendar Template.gsheet'\n",
            "-rw------- 1 root root      214 Oct 27 12:14 'Untitled spreadsheet (1).gsheet'\n",
            "-rw------- 1 root root      214 Oct 27 00:41 'Untitled spreadsheet (2).gsheet'\n",
            "-rw------- 1 root root      214 Nov  1 13:13 'Untitled spreadsheet.gsheet'\n",
            "-rw------- 1 root root      214 Nov 29 01:13 'VLOOKUP in Action Example.gsheet'\n",
            "-rw------- 1 root root      190 Nov 29 01:21 'VLOOKUP Practice Sheet.gsheet'\n",
            "-rw------- 1 root root      190 Aug  1  2023 \"Webi's task allocation .gsheet\"\n",
            "-rw------- 1 root root      190 Nov 30 00:23 'Working with Conditions.gsheet'\n"
          ]
        }
      ],
      "source": [
        "!ls -l \"/content/drive/My Drive\""
      ],
      "id": "z98_XfO7mFPz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4018c6ca"
      },
      "source": [
        "## Creating the policy model for human Evaluation"
      ],
      "id": "4018c6ca"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "f90da8c2"
      },
      "outputs": [],
      "source": [
        "df = pd.read_parquet(file_path) ## downloded above linked dataset,"
      ],
      "id": "f90da8c2"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "b00044d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b75e3c3-6607-4e8e-8101-292ece21c7c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "prompt    SUBREDDIT: r/tifu\\nTITLE: TIFU bY brushing wit...\n",
              "label     Brush Teeth with Baking Soda without research,...\n",
              "Name: 12, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df.iloc[12]"
      ],
      "id": "b00044d2"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ENcEzy5tmmNF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23afd063-6699-44ee-8d1d-4f347b6e4e41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ],
      "id": "ENcEzy5tmmNF"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0670ff5e"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class TLDRDataset(Dataset):\n",
        "    def __init__(self, train_path, tokenizer, split, max_length=256):\n",
        "        self.post_list = []\n",
        "        dataset = pd.read_parquet(train_path)\n",
        "        self.labels = []\n",
        "        dataset = dataset[:500]\n",
        "        for sample in dataset.iterrows():\n",
        "            self.post_list.append(sample[1][\"prompt\"])\n",
        "            self.labels.append(sample[1][\"label\"])\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.input_ids = []\n",
        "        self.attn_masks = []\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.post_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        txt = self.post_list[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        encodings_dict = self.tokenizer(txt, truncation=True, max_length=self.max_length, padding=\"max_length\")\n",
        "        encodings_dict_label = self.tokenizer(label,truncation=True, max_length=self.max_length, padding=\"max_length\")\n",
        "        input_ids = torch.tensor(encodings_dict[\"input_ids\"])\n",
        "        attn_masks = torch.tensor(encodings_dict[\"attention_mask\"])\n",
        "        labels_ids = torch.tensor(encodings_dict_label[\"input_ids\"])\n",
        "        return {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attn_masks,\n",
        "            \"labels\": labels_ids,\n",
        "        }\n",
        "\n"
      ],
      "id": "0670ff5e"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bced6616"
      },
      "outputs": [],
      "source": [
        "# for i in TLDRDataset():\n",
        "#     print(i)\n",
        "#     break"
      ],
      "id": "bced6616"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7f0a73ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35182805-83f5-475f-e4da-2fe6392c70a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bigcode/tiny_starcoder_py\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"bigcode/tiny_starcoder_py\", use_cache=False).to(\"cuda\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "model.config.end_token_id = tokenizer.eos_token_id\n",
        "model.config.pad_token_id = model.config.eos_token_id"
      ],
      "id": "7f0a73ab"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dbc6aad5"
      },
      "outputs": [],
      "source": [
        "# Set up the datasets\n",
        "data_path = \"/content/drive/My Drive/test.parquet\"\n",
        "train_dataset = TLDRDataset(\n",
        "    data_path,\n",
        "    tokenizer,\n",
        "    \"train\",\n",
        "    max_length=256,\n",
        ")\n",
        "# dev_dataset = TLDRDataset(\n",
        "#     data_path,\n",
        "#     tokenizer,\n",
        "#     \"valid\",\n",
        "#     max_length=max_input_length,\n",
        "# )\n"
      ],
      "id": "dbc6aad5"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "f16a19aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e11863c9-fc69-4956-8252-b2fdcc1a5c83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 7100,   613,  2918,   780,    44,   540,    33, 40186,   203, 13777,\n",
            "           44,  3110,   428,    35,    43,   506,    79,   623,  1672, 11970,\n",
            "          428,    35,    43,   488,   614,   646,  3654,   415,   439,  1631,\n",
            "         1159, 16661,  1246,  6366,   973,  3425,    32,   203,  3705,    44,\n",
            "        12000, 17964,  3638,  1548,    32,   439,  9845,   458,  7735,  1330,\n",
            "         5133, 31695,   432,   312,  7000,   372,  7660,   544,  2442,    30,\n",
            "         1273,   439,  4763,  2583, 42289,   312,  3493,   963,   432,  1672,\n",
            "         7713,  1412,   561, 12767,   372,   458, 18734,   308,    59,  4763,\n",
            "         5054,  1755,  1591, 12112,  2670,    30,   461,   436,  5075, 17510,\n",
            "           30,   561,  1597,   963,   432,   322, 48385,   547,   203,   203,\n",
            "         7558,   395,    19,  2770,    30,   312, 17142,   432, 22599, 14818,\n",
            "           30,   439,  7307, 29220,   372,   458,  3932,   107,   544, 18660,\n",
            "           30,  3919,   312,  9525,  2350,   688,   996,  4528,  4335,  1742,\n",
            "          432,    32,   439, 10889,   938,  1597,  3844,   432,   281,  1142,\n",
            "           30,  1259,   439,  4618, 10320,   312,  9396,  2258,   372, 12440,\n",
            "           30,  5774,    30,  5774,    32,  2688,  4484,  4335,  8872, 16512,\n",
            "          821,   322,  2432, 19076,    30,  1259,   439, 39271,   688,   996,\n",
            "         3065, 23840, 18450,   328,  4916,  5049,   996,  4335, 13639,   544,\n",
            "           31, 16033,   352,    32,  2770,    30,   996,  4142,    30,   461,\n",
            "          996,   420,  3280,   963,  8762, 19465,    30,  2258,   619, 22523,\n",
            "           32,   203,   203,  7558,   395,    32,  2770,    30,  8989,   438,\n",
            "         6783, 10191,  4487,    32,  2688, 12440,  2288, 18660,   461, 46438,\n",
            "         6172,    30, 17013,    32,  2770,    30,   358, 30288, 19212,    30,\n",
            "          439,  1597,  2258,   420,  7398,   963,   623,  7024,   461,  6186,\n",
            "          432,  3998,   323, 12837,    30,  1412,   439,  5424,   312, 46438,\n",
            "         6172,   645, 10320, 24240,  2769,   439]) tensor([   59,  6394,  2124,   458,  3932,   107,    30,  1273,  2685,  7696,\n",
            "        27082,   623, 10320,  2685,  1755, 44470, 10320,   436,   312,  5029,\n",
            "        25585,  7918,   432,  1133,    30,   439,  3860, 22958, 14051,   688,\n",
            "          439,  1631,  1159, 17090,  1441,  1672,   663,  3151,   432,   312,\n",
            "        12112,   623, 10320,    32,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n"
          ]
        }
      ],
      "source": [
        "for i in train_dataset:\n",
        "    print(i[\"input_ids\"], i[\"labels\"])\n",
        "    break"
      ],
      "id": "f16a19aa"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "500301ac"
      },
      "outputs": [],
      "source": [
        "\n",
        "torch.cuda.set_device(0)"
      ],
      "id": "500301ac"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QzSmRmrCpFNb"
      },
      "outputs": [],
      "source": [
        "\n",
        "from pathlib import Path\n",
        "output_dir = \"./output\"\n",
        "Path(output_dir).mkdir(parents=True, exist_ok=True)"
      ],
      "id": "QzSmRmrCpFNb"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9zSn_9QpaAy",
        "outputId": "422f7bb5-a3cb-472a-b0f5-9863763300ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.99)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "pip install accelerate -U"
      ],
      "id": "Y9zSn_9QpaAy"
    },
    {
      "cell_type": "code",
      "source": [
        "pip install accelerate>=0.21.0\n"
      ],
      "metadata": {
        "id": "TpioMYXP-3PJ"
      },
      "id": "TpioMYXP-3PJ",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade transformers accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkw_TYEdCZzO",
        "outputId": "e24232ac-b208-40aa-9215-96aa06ce8718"
      },
      "id": "pkw_TYEdCZzO",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.39.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.99)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "d3801788"
      },
      "outputs": [],
      "source": [
        "# Prepare the trainer and start training\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    learning_rate=learning_rate,\n",
        "    per_device_train_batch_size=train_batch_size,\n",
        "#     per_device_eval_batch_size=eval_batch_size,\n",
        "    fp16=False,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "    num_train_epochs=2,\n",
        "    warmup_steps=100,\n",
        "    logging_steps=10,\n",
        ")"
      ],
      "id": "d3801788"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "baefacaf"
      },
      "outputs": [],
      "source": [
        "#training_args.device.index"
      ],
      "id": "baefacaf"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "90ba4710",
        "outputId": "6aa74566-a0d6-4c75-90bc-d898c87544e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='64' max='64' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [64/64 01:21, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>10.264300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>6.583800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>2.592600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.515800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.193600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.080600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=64, training_loss=3.701623819768429, metrics={'train_runtime': 83.8055, 'train_samples_per_second': 11.932, 'train_steps_per_second': 0.764, 'total_flos': 184479645696000.0, 'train_loss': 3.701623819768429, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "#     compute_metrics=compute_metrics,\n",
        "#     data_collator=default_data_collator,\n",
        "#     preprocess_logits_for_metrics=preprocess_logits_for_metrics\n",
        ")\n",
        "trainer.train()\n",
        "# trainer.save_model(output_dir)"
      ],
      "id": "90ba4710"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "3dfc50c2"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(\"summarization_policy_new/\")   ##path to save policy model"
      ],
      "id": "3dfc50c2"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "b373c19c",
        "outputId": "d8fd7011-a40f-4dc4-b0ed-20df765c48bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"summarization_policy_new/\")\n",
        "model_path = \"bigcode/tiny_starcoder_py\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path, truncation=True, max_length=256, padding=\"max_length\")\n",
        "text = df.iloc[2][\"prompt\"]\n",
        "tokenized_text = tokenizer(text, return_tensors=\"pt\", max_length=256)"
      ],
      "id": "b373c19c"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "6dc7fe18",
        "outputId": "074ec7c2-0b2e-4bec-f988-f18309292b81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"SUBREDDIT: r/relationships\\nTITLE: The girl [26 F] I [22 M] have been seeing for a month didn't respond to me at all yesterday while hanging out with a friend [~30? M].\\nPOST: She gets terrible service while at her house, but I texted her 3 times yesterday, 4-5 hours apart. She didn't call me until early this morning and left a voicemail that she was busy all day with a friend who showed up out of the blue.\\n\\nI saw that she posted a picture of the two of them out of her dead zone house on facebook before I texted her the last time.\\n\\nI don't mind that she hangs out with friends, and I know it's pretty early in the relationship, but am I wrong to be a little annoyed that she didn't respond until 24 hours after my first text?\\nTL;DR: <|endoftext|>\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "tokenizer.decode(model.generate(**tokenized_text, max_new_tokens=183)[0])"
      ],
      "id": "6dc7fe18"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8421708e"
      },
      "source": [
        "## Traning the reward function"
      ],
      "id": "8421708e"
    },
    {
      "cell_type": "code",
      "source": [
        "pip install trl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmt3sl2g1oww",
        "outputId": "362e5d42-11d9-4fa3-c9cf-87312c596c14"
      },
      "id": "kmt3sl2g1oww",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: trl in /usr/local/lib/python3.10/dist-packages (0.8.1)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from trl) (2.2.1+cu121)\n",
            "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.10/dist-packages (from trl) (4.39.1)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.10/dist-packages (from trl) (1.25.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from trl) (0.28.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from trl) (2.18.0)\n",
            "Requirement already satisfied: tyro>=0.5.11 in /usr/local/lib/python3.10/dist-packages (from trl) (0.7.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->trl) (12.4.99)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (0.20.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (4.66.2)\n",
            "Requirement already satisfied: docstring-parser>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (13.7.1)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (1.7.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->trl) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (3.9.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.16.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4.0->trl) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2023.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets->trl) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "5b607ce4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import transformers\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, DataCollatorForLanguageModeling\n",
        "from trl import RewardTrainer, SFTTrainer\n",
        "from datasets import Dataset\n",
        "import json\n",
        "import pandas as pd\n",
        "from transformers import Trainer, TrainingArguments\n"
      ],
      "id": "5b607ce4"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "e849ca0f"
      },
      "outputs": [],
      "source": [
        "##model path\n",
        "MODEL_PATH = \"bigcode/tiny_starcoder_py\"\n",
        "DATA_PATH = \"/content/drive/My Drive/test2.parquet\""
      ],
      "id": "e849ca0f"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "14ddb7e5",
        "outputId": "90a5711a-3f75-48c7-967d-1dc62c2eab34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['prompt', 'chosen', 'rejected'],\n",
              "    num_rows: 10\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "df = pd.read_parquet(DATA_PATH)\n",
        "df = df[:10]\n",
        "raw_dataset = Dataset.from_pandas(df)\n",
        "raw_dataset"
      ],
      "id": "14ddb7e5"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "2209d915"
      },
      "outputs": [],
      "source": [
        "##defininig the model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_PATH)"
      ],
      "id": "2209d915"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "368defaa"
      },
      "outputs": [],
      "source": [
        "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "def formatting_func(examples):\n",
        "    kwargs = {\"padding\": \"max_length\",\n",
        "              \"truncation\": True,\n",
        "              \"max_length\": 256,\n",
        "              \"return_tensors\": \"pt\"\n",
        "              }\n",
        "\n",
        "    # Prepend the prompt and a line break to the original_response and response-1 fields.\n",
        "    prompt_plus_chosen_response = examples[\"prompt\"] + \"\\n\" + examples[\"chosen\"]\n",
        "    prompt_plus_rejected_response = examples[\"prompt\"] + \"\\n\" + examples[\"rejected\"]\n",
        "\n",
        "    # Then tokenize these modified fields.\n",
        "    tokens_chosen = tokenizer.encode_plus(prompt_plus_chosen_response, **kwargs)\n",
        "    tokens_rejected = tokenizer.encode_plus(prompt_plus_rejected_response, **kwargs)\n",
        "\n",
        "    return {\n",
        "        \"input_ids_chosen\": tokens_chosen[\"input_ids\"][0], \"attention_mask_chosen\": tokens_chosen[\"attention_mask\"][0],\n",
        "        \"input_ids_rejected\": tokens_rejected[\"input_ids\"][0], \"attention_mask_rejected\": tokens_rejected[\"attention_mask\"][0]\n",
        "    }"
      ],
      "id": "368defaa"
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you want to print the first record\n",
        "record = raw_dataset[0]\n",
        "print(record)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNILlssQEKZ8",
        "outputId": "c9f4b658-5915-4722-acf1-478f04335a86"
      },
      "id": "YNILlssQEKZ8",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'prompt': \"SUBREDDIT: r/relationships\\nTITLE: My [21/M] girlfriend [19/F] broke up with me after she went through my Facebook without my permission.\\nPOST: My girlfriend and I had been dating for 15 months. \\n\\n**Last week my girlfriend went onto my Facebook account and read through my message history with a couple of girls.**\\n\\nShe was **searching for a specific girl that I used to flirt with in the past, and she found it.**\\n\\nWe had fought one time before about me flirting with this girl, and I stopped talking to her entirely for a couple of months (obviously she didn't believe I did).\\n\\nShe found messages between the girl and I around my birthday in February, and her (message girl) birthday in June. Needless to say they were flirty but with no intentions of ever acting upon them. The girl lives in Europe and I live on the East Coast. But my girlfriend doesn't believe that I ever stopped talking to her, and that I was flirty throughout our entire relationship.\\n\\nI have no evidence to disprove this, except for the fact that I don't have her on social media anymore (excluding Facebook, which I now deleted)\\n\\nYes I know it was stupid for me to flirt in the first place, but I can't help but feel like there is a massive invasion of privacy and that she shouldn't have seen the messages in the first place.\", 'chosen': 'TL;DR:  My Girlfriend of 15 months went through my Facebook messages without my permission and found old conversations of me flirting with a girl. She broke up with me and went no contact.', 'rejected': 'TL;DR:  My girlfriend and I broke up after she went through my Facebook account without my permission.<|endoftext|>Citizens for the Republic'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(raw_dataset[0].keys()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDp2FFQpFwrE",
        "outputId": "0ef3834b-0869-4654-faad-78cf914a1384"
      },
      "id": "cDp2FFQpFwrE",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['prompt', 'chosen', 'rejected']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def formatting_func(example):\n",
        "#     # Modify the function to work with the correct keys\n",
        "#     return {\n",
        "#         'prompt': example['prompt'],   # Access the 'prompt' key\n",
        "#         'chosen': example['chosen'],   # Access the 'chosen' key\n",
        "#         'rejected': example['rejected']  # Access the 'rejected' key\n",
        "#     }\n"
      ],
      "metadata": {
        "id": "9HbqO0VPJ0hV"
      },
      "id": "9HbqO0VPJ0hV",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "ba0d353034034f509ce2cc38b5909ded",
            "fe9d90cc5ec04f0fa96a578b70c27628",
            "83b00d2b2d4d432e97bbf4e5358c891a",
            "0b6eb18d8d5642089643e984197f9877",
            "9866d4c60d6a44e3944307e7294b62e7",
            "c15a6a9393b247fabe85d43797a9f3c9",
            "e946f086cb4c41ba87979b71a8f84262",
            "6f45792993e94d5c88712f435021f3ce",
            "8112629c0589459c82df02ea216c9018",
            "8f8e8c2e7ee1452abdfbb835d502555f",
            "6bacb60b088546efb541abfd0a9733da"
          ]
        },
        "id": "0f4afbee",
        "outputId": "d81463c7-1ecb-4348-b69d-fc0e08a3cdf4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ba0d353034034f509ce2cc38b5909ded"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "formatted_dataset = raw_dataset.map(formatting_func)\n",
        "formatted_dataset = formatted_dataset.train_test_split()"
      ],
      "id": "0f4afbee"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "43490bac",
        "outputId": "149ab3cd-fe1d-4695-96dc-bc437bbcd482",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTBigCodeConfig {\n",
              "  \"_name_or_path\": \"bigcode/tiny_starcoder_py\",\n",
              "  \"activation_function\": \"gelu_pytorch_tanh\",\n",
              "  \"architectures\": [\n",
              "    \"GPTBigCodeForCausalLM\"\n",
              "  ],\n",
              "  \"attention_softmax_in_fp32\": true,\n",
              "  \"attn_pdrop\": 0.1,\n",
              "  \"bos_token_id\": 0,\n",
              "  \"embd_pdrop\": 0.1,\n",
              "  \"eos_token_id\": 0,\n",
              "  \"inference_runner\": 0,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"layer_norm_epsilon\": 1e-05,\n",
              "  \"max_batch_size\": null,\n",
              "  \"max_sequence_length\": null,\n",
              "  \"model_type\": \"gpt_bigcode\",\n",
              "  \"multi_query\": true,\n",
              "  \"n_embd\": 768,\n",
              "  \"n_head\": 12,\n",
              "  \"n_inner\": 3072,\n",
              "  \"n_layer\": 20,\n",
              "  \"n_positions\": 8192,\n",
              "  \"pad_key_length\": true,\n",
              "  \"pre_allocate_kv_cache\": false,\n",
              "  \"resid_pdrop\": 0.1,\n",
              "  \"scale_attention_softmax_in_fp32\": true,\n",
              "  \"scale_attn_weights\": true,\n",
              "  \"summary_activation\": null,\n",
              "  \"summary_first_dropout\": 0.1,\n",
              "  \"summary_proj_to_labels\": true,\n",
              "  \"summary_type\": \"cls_index\",\n",
              "  \"summary_use_proj\": true,\n",
              "  \"torch_dtype\": \"float32\",\n",
              "  \"transformers_version\": \"4.39.1\",\n",
              "  \"use_cache\": true,\n",
              "  \"validate_runner_input\": true,\n",
              "  \"vocab_size\": 49152\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "model.config"
      ],
      "id": "43490bac"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "dce3aef6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cbc6deb-edf7-4f40-ad8e-369458525f45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1399: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of  Transformers. Use `use_cpu` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "### Loading the TRL reward trainer and training the trainer\n",
        "training_args = TrainingArguments(\n",
        "        output_dir=\"rm_checkpoint/\",\n",
        "        num_train_epochs=1,\n",
        "        logging_steps=10,\n",
        "        gradient_accumulation_steps=1,\n",
        "        save_strategy=\"steps\",\n",
        "        evaluation_strategy=\"steps\",\n",
        "        per_device_train_batch_size=2,\n",
        "        per_device_eval_batch_size=1,\n",
        "        eval_accumulation_steps=1,\n",
        "        eval_steps=500,\n",
        "        save_steps=500,\n",
        "        warmup_steps=100,\n",
        "        logging_dir=\"./logs\",\n",
        "        learning_rate=1e-5,\n",
        "        save_total_limit=1,\n",
        "        no_cuda=True\n",
        "    )"
      ],
      "id": "dce3aef6"
    },
    {
      "cell_type": "code",
      "source": [
        "# def formatting_func(example):\n",
        "#     # Tokenize the prompt text for chosen and rejected actions\n",
        "#     chosen_inputs = tokenizer(example['prompt'], truncation=True, padding='max_length', max_length=128)\n",
        "#     rejected_inputs = tokenizer(example['prompt'], truncation=True, padding='max_length', max_length=128)\n",
        "\n",
        "#     # Construct the final example with all required keys\n",
        "#     processed_example = {\n",
        "#         'input_ids_chosen': chosen_inputs['input_ids'],\n",
        "#         'attention_mask_chosen': chosen_inputs['attention_mask'],\n",
        "#         'input_ids_rejected': rejected_inputs['input_ids'],\n",
        "#         'attention_mask_rejected': rejected_inputs['attention_mask'],\n",
        "#         'labels': example['label']  # Assuming 'label' contains the label for the example\n",
        "#     }\n",
        "\n",
        "#     return processed_example\n"
      ],
      "metadata": {
        "id": "N1OcCd6lsK4v"
      },
      "id": "N1OcCd6lsK4v",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "d06ad45a"
      },
      "outputs": [],
      "source": [
        "# def process_example(example):\n",
        "#     # Tokenize the prompt text for chosen and rejected actions\n",
        "#     chosen_inputs = tokenizer(example['prompt'], truncation=True, padding='max_length', max_length=128)\n",
        "#     rejected_inputs = tokenizer(example['prompt'], truncation=True, padding='max_length', max_length=128)\n",
        "\n",
        "#     # Check if tokenized inputs exceed the maximum length\n",
        "#     max_length = tokenizer.model_max_length\n",
        "#     if len(chosen_inputs['input_ids']) > max_length:\n",
        "#         chosen_inputs = tokenizer(example['prompt'], truncation=True, padding='max_length', max_length=max_length)\n",
        "#     if len(rejected_inputs['input_ids']) > max_length:\n",
        "#         rejected_inputs = tokenizer(example['prompt'], truncation=True, padding='max_length', max_length=max_length)\n",
        "\n",
        "#     # Construct the final example with all required keys\n",
        "#     processed_example = {\n",
        "#         'input_ids_chosen': chosen_inputs['input_ids'],\n",
        "#         'attention_mask_chosen': chosen_inputs['attention_mask'],\n",
        "#         'input_ids_rejected': rejected_inputs['input_ids'],\n",
        "#         'attention_mask_rejected': rejected_inputs['attention_mask'],\n",
        "#         'labels': example['chosen']  # Assuming 'chosen' contains the label for the example\n",
        "#     }\n",
        "\n",
        "#     return processed_example\n"
      ],
      "id": "d06ad45a"
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = RewardTrainer(model=model,\n",
        "                        tokenizer=tokenizer,\n",
        "                        train_dataset=formatted_dataset['train'],\n",
        "                        eval_dataset=formatted_dataset['test'],\n",
        "                        args= training_args\n",
        "                        )\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "OqXKHjVBmNlr",
        "outputId": "10012ba0-75db-4a36-d903-76ab1b833792"
      },
      "id": "OqXKHjVBmNlr",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/reward_trainer.py:110: FutureWarning: Using `transformers.TrainingArguments` for `args` is deprecated and will be removed in a future version. Please use `RewardConfig` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/reward_trainer.py:164: UserWarning: When using RewardDataCollatorWithPadding, you should set `max_length` in RewardConfig. It will be set to `512` by default, but you should do it yourself in the future.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/reward_trainer.py:189: UserWarning: When using RewardDataCollatorWithPadding, you should set `remove_unused_columns=False` in your RewardConfig we have set it for you, but you should do it yourself in the future.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n",
            "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2706: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4/4 00:33, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=4, training_loss=0.7631032466888428, metrics={'train_runtime': 48.2685, 'train_samples_per_second': 0.145, 'train_steps_per_second': 0.083, 'total_flos': 0.0, 'train_loss': 0.7631032466888428, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "c8620e81"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(\"rm_model/\")"
      ],
      "id": "c8620e81"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "1d56a13c"
      },
      "outputs": [],
      "source": [
        "## inference the model\n",
        "rm_model = AutoModelForCausalLM.from_pretrained(\"rm_model/\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"rm_model/\")"
      ],
      "id": "1d56a13c"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "e694fbc6"
      },
      "outputs": [],
      "source": [
        "def get_score(model, tokenizer, prompt, response):\n",
        "\n",
        "    instructions = tokenizer.encode_plus(prompt,\n",
        "                                       response,\n",
        "                                       padding=\"max_length\",\n",
        "                                       max_length=256,\n",
        "                                       return_tensors=\"pt\",\n",
        "                                        truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**instructions)\n",
        "\n",
        "    logits = outputs[0]\n",
        "\n",
        "    return logits\n"
      ],
      "id": "e694fbc6"
    },
    {
      "cell_type": "code",
      "source": [
        "# Print all column names in the DataFrame\n",
        "print(df.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZDL1H_4PIuK",
        "outputId": "64c18750-cde1-4df6-d30f-b758073d02b4"
      },
      "id": "hZDL1H_4PIuK",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['prompt', 'chosen', 'rejected'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "ed481305"
      },
      "outputs": [],
      "source": [
        "# usage with prompt\n",
        "prompt = df.iloc[0][\"prompt\"]\n",
        "example_prefered_response = df.iloc[0][\"chosen\"]\n",
        "example_unprefered_response = df.iloc[0][\"rejected\"]"
      ],
      "id": "ed481305"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "1d513768"
      },
      "outputs": [],
      "source": [
        "loss1 = get_score(model, tokenizer, prompt, example_prefered_response)\n",
        "loss2= get_score(model, tokenizer, prompt, example_unprefered_response)"
      ],
      "id": "1d513768"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "bc95e92f"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "loss = -nn.functional.logsigmoid(loss1 - loss2).mean()"
      ],
      "id": "bc95e92f"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "1c5e14b4",
        "outputId": "61b6efdc-7feb-44d5-9610-ad22379ac1b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'_DDIT_\\n           \"r/\\n: \" Relationship10]0]\\nlsriend\\n29/M]\\n [\\n [\\n  was to the [\\n a friends to\\n\\n: < [lfriend [ gir am a aressed. my10 minutes.\\n\\n\"\"\"1 updated:** girlfriend and through my Facebook.. I out my Facebook.**. a few of lf**\\n\\n** went dd for for my gir personirl** I was to findoolpp the my my future. and I was a in\\n\\n** have **li the of to she.liting me my girl. and she had the to me.. me few of gir.1viously). was\\'t find that was not\\n\\n** was her for my girl and the was the Facebook. the   she herand historyirl) was was February,\\n to, f that were flited. I her mores. my.ing on her.\\nirirl wasD; I1 girirllfriend, 19 months. to my Facebook account. my permission. I them messages. her.lirting with her coupleirl.\\n found up with me after I through more with\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "tokenizer.decode(torch.max(loss1, axis=-1).indices[0])"
      ],
      "id": "1c5e14b4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92769534"
      },
      "source": [
        "# Policy Model"
      ],
      "id": "92769534"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "bb9cb217"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import transformers\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, DataCollatorForLanguageModeling\n",
        "from trl import RewardTrainer, SFTTrainer\n",
        "from datasets import Dataset\n",
        "import json\n",
        "import pandas as pd\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from trl import PPOTrainer, PPOConfig, AutoModelForCausalLMWithValueHead, create_reference_model"
      ],
      "id": "bb9cb217"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "50d0acdb"
      },
      "outputs": [],
      "source": [
        "##model path\n",
        "MODEL_PATH = \"rm_model/\"\n",
        "DATA_PATH = \"/content/drive/My Drive/test2.parquet\""
      ],
      "id": "50d0acdb"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "221cfe68",
        "outputId": "6ba2e2e5-86b3-4ac1-fa55-00a9a3acbc8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['prompt', 'chosen', 'rejected'],\n",
              "    num_rows: 1000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "df = pd.read_parquet(DATA_PATH)\n",
        "df = df[:1000]\n",
        "dataset = Dataset.from_pandas(df)\n",
        "dataset"
      ],
      "id": "221cfe68"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "05f02097"
      },
      "outputs": [],
      "source": [
        "sentiment_pipe_kwargs = {\"top_k\": None, \"function_to_apply\": \"none\"}\n",
        "\n",
        "config = PPOConfig(\n",
        "    model_name=MODEL_PATH, steps=51200, learning_rate=1.41e-5, remove_unused_columns=True\n",
        ")\n",
        "\n",
        "txt_in_len = 5\n",
        "txt_out_len = 20\n",
        "seed = 1"
      ],
      "id": "05f02097"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "6e5769b3"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, pipeline"
      ],
      "id": "6e5769b3"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "ff51d5403b4c4e38a8f38601b1afa760",
            "a38a97eb8c6146278c2794f9a802b531",
            "ed80a1661b6b4ab09243250d962ebd4d",
            "36c6a5d7d2c242769a64c5adc14b5da6",
            "4d23103ea52c456c851747ffe3bb25fa",
            "5f0aef3310714c3dbfcaf3f18b14bb5b",
            "9716b4dc9be640b0a417d1de01c30775",
            "5b569b8214934aa6bd9230311362e839",
            "1642f6e858d844b19f104c1bf44ec967",
            "eb46e6833657484aadd3eae0c917aaf0",
            "fde77c0649d149988f81ee8be2a2e615",
            "ee57312889904b9895b28569a2ae5e92",
            "a4c45a7760e84b56802cf6e92e75df2e",
            "1f5f67bbd50d40a4af498f6ec9f5f750",
            "91a266f0eb5d439d8e1c01f63194bd39",
            "0ea77d24d7ff49c990c25d7ba8fad193",
            "4088c52969bc4596ba2ab2f9c798c2cc",
            "b1ac4461e5e244dc9faf6d25b0e42462",
            "4eebff02efec4dd9a5778f424864be4c",
            "9ce30c9a21274e008ea2b7a18b8e47d8",
            "e8fec26aee854fdd87074679b249c932",
            "4dfcde6e63d54f62a95763a55d640408"
          ],
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "40d0ef6a",
        "outputId": "62e1d677-47bf-4cbe-a318-7454dd9ddb26"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff51d5403b4c4e38a8f38601b1afa760"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee57312889904b9895b28569a2ae5e92"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "dataset = dataset.rename_columns({\"prompt\": \"review\"})\n",
        "dataset = dataset.filter(lambda x: len(x[\"review\"]) > 500, batched=False)\n",
        "dataset = dataset.map(lambda x: {\"review\": x[\"review\"][:1000]}, batched=False)"
      ],
      "id": "40d0ef6a"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "96d7e8b8"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, padding_side='left')\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "id": "96d7e8b8"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "4bdc3041fa924382be9564b7050adff3",
            "46b4dd64e46147a0970315503528d2fa",
            "88265476c2b948db890113e8c24ad419",
            "1422590bb77e442bbc32b8393d997041",
            "b03d811a3cb9427ca09092d56b1aa0cb",
            "ba29a0e0408e4ccdbb8f1086f2688dd3",
            "5364964182094a868638b735b838059e",
            "72dc93bcd84c4a75baf4ad789edfd6c3",
            "833e4c9402234555aa32a7da1efce69e",
            "bbab3564b98740ebac79a4bbbcfa8e89",
            "2b8cc216305843048f3b4e6361947e93",
            "806612ba48d64423b5f7b57e07deb980",
            "80a2bc7658eb4827a31961eeb74b53bc",
            "b94d4a9cd58743f58a4d906809d559ee",
            "ea7dd1d64356456abc4dc28ab5bf6e51",
            "099c7a8fcf8047598dc69cb56406f7bd",
            "c6fdb9021d964411a1930c6b499868e7",
            "6c2a315cffb148aab52b9513ab40687a",
            "4419339113c040f2ba3716bf64db0ee3",
            "9d4e91b84e0b4f1e912832a4e4c42be1",
            "3d2c53f3d65749ea9bcd53497dcfed86",
            "8535288e565e452cbcb1aa156b5dd2e5"
          ],
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "3adda4dc",
        "outputId": "65a7ce54-c3d8-4770-92aa-001839e44930"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4bdc3041fa924382be9564b7050adff3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "806612ba48d64423b5f7b57e07deb980"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "txt_in_len = 5\n",
        "txt_out_len = 32\n",
        "seed = 1\n",
        "\n",
        "dataset = dataset.map(\n",
        "    lambda x: {\"input_ids\": tokenizer.encode(\" \" + x[\"chosen\"], return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=32)[0]},\n",
        "    batched=False,\n",
        ")\n",
        "dataset = dataset.map(lambda x: {\"query\": tokenizer.decode(x[\"input_ids\"])}, batched=False)\n",
        "dataset = dataset[:20480]\n",
        "from datasets import Dataset\n",
        "\n",
        "dataset = Dataset.from_dict(dataset)\n",
        "dataset.set_format(\"pytorch\")"
      ],
      "id": "3adda4dc"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "e189a22b"
      },
      "outputs": [],
      "source": [
        "def collator(data):\n",
        "    return dict((key, [d[key] for d in data]) for key in data[0])"
      ],
      "id": "e189a22b"
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "cc612f5f"
      },
      "outputs": [],
      "source": [
        "rf_model_path = \"rm_model/\"\n",
        "starcoder_model = AutoModelForCausalLMWithValueHead.from_pretrained(\"summarization_policy_new/\")  ##policy model from step 1\n",
        "starcoder_model_ref = AutoModelForCausalLMWithValueHead.from_pretrained(rf_model_path) ## reward model from step 2\n",
        "starcoder_tokenizer = AutoTokenizer.from_pretrained(\"bigcode/tiny_starcoder_py\") ## tokenizer of step 1 model., here since we are using same model for step 1 and 2 it doesnot matter"
      ],
      "id": "cc612f5f"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "2836e5cc",
        "outputId": "92dd2c12-1247-4329-d99a-0f36fa403328",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['review', 'chosen', 'rejected', 'input_ids', 'query'],\n",
              "    num_rows: 1000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "dataset"
      ],
      "id": "2836e5cc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4800d3e9"
      },
      "outputs": [],
      "source": [
        "# starcoder_model"
      ],
      "id": "4800d3e9"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "2e1a2e38"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "optimizer = torch.optim.SGD(starcoder_model.parameters(), lr=config.learning_rate)\n",
        "ppo_trainer = PPOTrainer(config, starcoder_model, starcoder_model, starcoder_tokenizer, dataset=dataset, data_collator=collator, optimizer=optimizer)"
      ],
      "id": "2e1a2e38"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "e63e72ad"
      },
      "outputs": [],
      "source": [
        "# for i in ppo_trainer.dataloader:\n",
        "#   print(i)\n",
        "#   break"
      ],
      "id": "e63e72ad"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "e329e292"
      },
      "outputs": [],
      "source": [
        "ctrl_str = [\"[negative]\", \"[positive]\"]\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # this should be handled by accelerate\n",
        "ctrl_tokens = dict((s, starcoder_tokenizer.encode(s, return_tensors=\"pt\").squeeze().to(device)) for s in ctrl_str)\n"
      ],
      "id": "e329e292"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "597ac197"
      },
      "outputs": [],
      "source": [
        "def pos_logit_to_reward(logit, task):\n",
        "    \"\"\"\n",
        "    Take the positive sentiment logit and scale it for the task.\n",
        "        task [negative]: reward = -logit\n",
        "        task [neutral]: reward = -2*abs(logit)+4\n",
        "        task [positive]: reward = logit\n",
        "    \"\"\"\n",
        "    for i in range(len(logit)):\n",
        "        if task[i] == \"[negative]\":\n",
        "            logit[i] = -logit[i]\n",
        "        elif task[i] == \"[positive]\":\n",
        "            pass\n",
        "        else:\n",
        "            raise ValueError(\"task has to be in [0, 1, 2]!\")\n",
        "    return logit"
      ],
      "id": "597ac197"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "8a916542",
        "outputId": "4a986be2-5b73-43c5-e8e3-0957bfc9e913",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-4.,  4.])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "pos_logit_to_reward(torch.Tensor([4, 4]), ctrl_str)"
      ],
      "id": "8a916542"
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "2974cb44"
      },
      "outputs": [],
      "source": [
        "generation_kwargs = {\n",
        "    \"min_length\": -1,\n",
        "    \"top_k\": 0.0,\n",
        "    \"top_p\": 1.0,\n",
        "    \"do_sample\": True,\n",
        "    \"pad_token_id\": starcoder_tokenizer.eos_token_id,\n",
        "    \"max_new_tokens\": 32,\n",
        "    \"eos_token_id\": -1,\n",
        "}"
      ],
      "id": "2974cb44"
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "27cf0762"
      },
      "outputs": [],
      "source": [
        "def get_score(model, tokenizer, responses):\n",
        "    positive_logist = []\n",
        "    for i in responses:\n",
        "        instructions = tokenizer.encode_plus(\n",
        "                                           i,\n",
        "                                           padding=\"max_length\",\n",
        "                                           max_length=32,\n",
        "                                           return_tensors=\"pt\")\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**instructions)\n",
        "\n",
        "        logits = outputs[0].mean()\n",
        "        positive_logist.append(logits)\n",
        "\n",
        "    return positive_logist\n"
      ],
      "id": "27cf0762"
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "41d47d37"
      },
      "outputs": [],
      "source": [
        "# responses =[\"ashish is a goo\", \"heelow how are you\", \"__IT_\\nr/\\n: r RelationshipRelationship]]0]\\nlsriend\\n2//M]\\n [ [ a\\n the was to the [. a friends to\\n\\n:\\n [lfriend [ me have a aried in his19 minutes.\\n\\nWhat Modified:** girlfriend was through the Facebook.. I my my friends.**** my  of lf**\\n\\n** was d1ing for my few personirl** I had for findoolpping my my the future** but I was that in\\n\\n** have ali  of to she  tolirt my me girl. and she found my about my.. me few of gir.1viously). was\\'t find her was).\\n\\n** was it about my twoirl and the had  Facebook. the  and she gand historyirl) was in April,\\n to, find, were flirted. I a messages.. f.ing on her.\\n girlM\\n; I1 girirllfriend and the19 months. to my Facebook.. my permission. she her messages. my.lirty with my fewirl.\\n found her with me. I through more with\\n\"]\n",
        "# get_score(starcoder_model, tokenizer, responses)"
      ],
      "id": "41d47d37"
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "8b9e99bd"
      },
      "outputs": [],
      "source": [],
      "id": "8b9e99bd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "84898817-5381-4656-d0de-75c7dc80803d",
        "id": "CYZNfWCC01W_"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r",
            "  0%|                                                                                                                        | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['[negative]', '[positive]']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r",
            " 33%|                                                                         | 1/3 [25:43<51:27, 1543.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['[negative]', '[positive]']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r",
            " 67%|                                    | 2/3 [49:32<24:36, 1476.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['[negative]', '[positive]']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 3/3 [1:13:37<00:00, 1472.59s/it]\n"
          ]
        }
      ],
      "source": [
        "from random import choices\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "for epoch in range(1):\n",
        "    for batch in tqdm(ppo_trainer.dataloader):\n",
        "        (logs, game_data,) = (\n",
        "            dict(),\n",
        "            dict(),\n",
        "        )\n",
        "\n",
        "        print(ctrl_str)\n",
        "        #### prepend a random control token\n",
        "        task_list = choices(ctrl_str, k=config.batch_size)\n",
        "        game_data[\"query\"] = [t + q for t, q in zip(task_list, batch[\"query\"])]\n",
        "        query_tensors = [torch.cat((ctrl_tokens[t], input_ids)) for t, input_ids in zip(task_list, batch[\"input_ids\"])]\n",
        "\n",
        "        #### get response from gpt2\n",
        "        response_tensors = []\n",
        "        for query in query_tensors:\n",
        "            response = ppo_trainer.generate(query, **generation_kwargs)\n",
        "            response_tensors.append(response.squeeze()[-txt_out_len:])\n",
        "#         print(response_tensors)\n",
        "        game_data[\"response\"] = [starcoder_tokenizer.decode(r.squeeze()) for r in response_tensors]\n",
        "\n",
        "        #### sentiment analysis\n",
        "        texts = [q + r for q, r in zip(batch[\"query\"], game_data[\"response\"])]\n",
        "        logits = get_score(starcoder_model,starcoder_tokenizer, texts)\n",
        "        rewards = pos_logit_to_reward(logits, task_list)\n",
        "\n",
        "        #### Run PPO training\n",
        "        t = time.time()\n",
        "        stats = ppo_trainer.step(query_tensors, response_tensors, rewards)\n",
        "\n",
        "        for cs in ctrl_str:\n",
        "            key = \"env/reward_\" + cs.strip(\"[]\")\n",
        "            stats[key] = np.mean([r.cpu().numpy() for r, t in zip(rewards, task_list) if t == cs])\n",
        "        ppo_trainer.log_stats(stats, game_data, rewards)"
      ],
      "id": "CYZNfWCC01W_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0bad48f",
        "outputId": "dba21dc2-3836-4df1-a87c-f201eaf126fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('rhlfmodel/tokenizer_config.json',\n",
              " 'rhlfmodel/special_tokens_map.json',\n",
              " 'rhlfmodel/vocab.json',\n",
              " 'rhlfmodel/merges.txt',\n",
              " 'rhlfmodel/added_tokens.json',\n",
              " 'rhlfmodel/tokenizer.json')"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "###saving the model\n",
        "starcoder_model.save_pretrained(\"rhlfmodel/\")\n",
        "starcoder_tokenizer.save_pretrained(\"rhlfmodel/\")"
      ],
      "id": "d0bad48f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23bf2489",
        "outputId": "314e7241-83ab-4e3e-ccb2-79fe49813dd4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at rhlfmodel/ were not used when initializing GPTBigCodeForCausalLM: ['v_head.summary.bias', 'v_head.summary.weight']\n",
            "- This IS expected if you are initializing GPTBigCodeForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing GPTBigCodeForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline, set_seed\n",
        "model_path = \"rhlfmodel/\"\n",
        "set_seed(42)\n",
        "pipe = pipeline(\"text-generation\",model=model_path, tokenizer=model_path, max_length=30, num_return_sequences=5)"
      ],
      "id": "23bf2489"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "026e2c6c"
      },
      "outputs": [],
      "source": [
        "# text = dataset[\"rejected\"][0]\n",
        "# pipe(text)"
      ],
      "id": "026e2c6c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85b6a2e4"
      },
      "outputs": [],
      "source": [
        "# text"
      ],
      "id": "85b6a2e4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8e8d8135",
        "outputId": "c7f23370-09e6-4305-eee5-32428a000dd7",
        "scrolled": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'objective/kl': 0.0,\n",
              " 'objective/kl_dist': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0.], dtype=float32),\n",
              " 'objective/logprobs': array([[-2.4248543e+01, -1.4291405e+01, -2.6734692e+01, ...,\n",
              "         -3.1947580e-05, -3.2424403e-05, -3.5285328e-05],\n",
              "        [-2.5522242e+01, -1.4627422e+01, -2.7209345e+01, ...,\n",
              "         -2.9682673e-05, -3.0278701e-05, -3.2901222e-05],\n",
              "        [-2.4248543e+01, -1.4291405e+01, -2.6734692e+01, ...,\n",
              "         -3.3735661e-05, -3.4450892e-05, -3.7550220e-05],\n",
              "        ...,\n",
              "        [-2.4248543e+01, -1.4291405e+01, -9.7971582e+00, ...,\n",
              "         -3.0874729e-05, -3.1232346e-05, -3.3735661e-05],\n",
              "        [-2.5522242e+01, -1.4627422e+01, -2.7209345e+01, ...,\n",
              "         -2.8729026e-05, -2.9325056e-05, -3.1828375e-05],\n",
              "        [-2.4248543e+01, -1.4291405e+01, -9.7971582e+00, ...,\n",
              "         -3.1470758e-05, -3.1828375e-05, -3.4450892e-05]], dtype=float32),\n",
              " 'objective/ref_logprobs': array([[-2.4248543e+01, -1.4291405e+01, -2.6734692e+01, ...,\n",
              "         -3.1947580e-05, -3.2424403e-05, -3.5285328e-05],\n",
              "        [-2.5522242e+01, -1.4627422e+01, -2.7209345e+01, ...,\n",
              "         -2.9682673e-05, -3.0278701e-05, -3.2901222e-05],\n",
              "        [-2.4248543e+01, -1.4291405e+01, -2.6734692e+01, ...,\n",
              "         -3.3735661e-05, -3.4450892e-05, -3.7550220e-05],\n",
              "        ...,\n",
              "        [-2.4248543e+01, -1.4291405e+01, -9.7971582e+00, ...,\n",
              "         -3.0874729e-05, -3.1232346e-05, -3.3735661e-05],\n",
              "        [-2.5522242e+01, -1.4627422e+01, -2.7209345e+01, ...,\n",
              "         -2.8729026e-05, -2.9325056e-05, -3.1828375e-05],\n",
              "        [-2.4248543e+01, -1.4291405e+01, -9.7971582e+00, ...,\n",
              "         -3.1470758e-05, -3.1828375e-05, -3.4450892e-05]], dtype=float32),\n",
              " 'objective/kl_coef': 0.19694370179645443,\n",
              " 'objective/entropy': 1.6749732494354248,\n",
              " 'ppo/mean_non_score_reward': 0.0,\n",
              " 'ppo/mean_scores': -0.12584742903709412,\n",
              " 'ppo/std_scores': 5.42613410949707,\n",
              " 'tokens/queries_len_mean': 35.0,\n",
              " 'tokens/queries_len_std': 0.0,\n",
              " 'tokens/queries_dist': array([35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35.,\n",
              "        35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35.,\n",
              "        35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35.,\n",
              "        35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35.,\n",
              "        35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35.,\n",
              "        35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35.,\n",
              "        35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35.,\n",
              "        35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35.,\n",
              "        35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35.,\n",
              "        35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35.,\n",
              "        35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35.,\n",
              "        35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35.,\n",
              "        35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35.,\n",
              "        35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35.,\n",
              "        35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35.,\n",
              "        35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35.,\n",
              "        35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35.,\n",
              "        35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35.,\n",
              "        35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35., 35.,\n",
              "        35., 35., 35., 35., 35., 35., 35., 35., 35.], dtype=float32),\n",
              " 'tokens/responses_len_mean': 32.0,\n",
              " 'tokens/responses_len_std': 0.0,\n",
              " 'tokens/responses_dist': array([32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32.,\n",
              "        32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32.,\n",
              "        32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32.,\n",
              "        32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32.,\n",
              "        32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32.,\n",
              "        32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32.,\n",
              "        32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32.,\n",
              "        32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32.,\n",
              "        32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32.,\n",
              "        32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32.,\n",
              "        32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32.,\n",
              "        32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32.,\n",
              "        32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32.,\n",
              "        32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32.,\n",
              "        32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32.,\n",
              "        32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32.,\n",
              "        32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32.,\n",
              "        32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32.,\n",
              "        32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32., 32.,\n",
              "        32., 32., 32., 32., 32., 32., 32., 32., 32.], dtype=float32),\n",
              " 'ppo/loss/policy': -0.00010979006765410304,\n",
              " 'ppo/loss/value': 5.189159870147705,\n",
              " 'ppo/loss/total': 0.5188061594963074,\n",
              " 'ppo/policy/entropy': 0.0009501720196567476,\n",
              " 'ppo/policy/approxkl': 2.324135675735306e-05,\n",
              " 'ppo/policy/policykl': 2.1984804334351793e-05,\n",
              " 'ppo/policy/clipfrac': 0.000244140625,\n",
              " 'ppo/policy/advantages': array([1.8667955, 1.8631277, 1.8592668, ..., 0.8031267, 2.2571814,\n",
              "        1.3958192], dtype=float32),\n",
              " 'ppo/policy/advantages_mean': 4.2527972254902124e-09,\n",
              " 'ppo/policy/ratio': array([1.        , 1.        , 1.        , ..., 0.9999918 , 0.99999154,\n",
              "        0.99999094], dtype=float32),\n",
              " 'ppo/returns/mean': 0.21962669491767883,\n",
              " 'ppo/returns/var': 1.6779695749282837,\n",
              " 'ppo/val/vpred': 0.4521799087524414,\n",
              " 'ppo/val/error': 9.344433784484863,\n",
              " 'ppo/val/clipfrac': 0.394866943359375,\n",
              " 'ppo/val/mean': 0.5472686290740967,\n",
              " 'ppo/val/var': 0.22415316104888916,\n",
              " 'ppo/time/ppo/optimizer_step': 0.12164130806922913,\n",
              " 'ppo/val/var_explained': -4.5688934326171875,\n",
              " 'ppo/learning_rate': 1.41e-05,\n",
              " 'time/ppo/forward_pass': 84.3550615310669,\n",
              " 'time/ppo/compute_rewards': 0.015000104904174805,\n",
              " 'time/ppo/optimize_step': 1003.6978762149811,\n",
              " 'time/ppo/calc_stats': 0.17599773406982422,\n",
              " 'time/ppo/total': 1088.264935016632,\n",
              " 'env/reward_negative': 5.415969,\n",
              " 'env/reward_positive': -5.41384}"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stats"
      ],
      "id": "8e8d8135"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2f478497"
      },
      "outputs": [],
      "source": [],
      "id": "2f478497"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ba0d353034034f509ce2cc38b5909ded": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe9d90cc5ec04f0fa96a578b70c27628",
              "IPY_MODEL_83b00d2b2d4d432e97bbf4e5358c891a",
              "IPY_MODEL_0b6eb18d8d5642089643e984197f9877"
            ],
            "layout": "IPY_MODEL_9866d4c60d6a44e3944307e7294b62e7"
          }
        },
        "fe9d90cc5ec04f0fa96a578b70c27628": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c15a6a9393b247fabe85d43797a9f3c9",
            "placeholder": "",
            "style": "IPY_MODEL_e946f086cb4c41ba87979b71a8f84262",
            "value": "Map:100%"
          }
        },
        "83b00d2b2d4d432e97bbf4e5358c891a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f45792993e94d5c88712f435021f3ce",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8112629c0589459c82df02ea216c9018",
            "value": 10
          }
        },
        "0b6eb18d8d5642089643e984197f9877": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f8e8c2e7ee1452abdfbb835d502555f",
            "placeholder": "",
            "style": "IPY_MODEL_6bacb60b088546efb541abfd0a9733da",
            "value": "10/10[00:00&lt;00:00,48.51examples/s]"
          }
        },
        "9866d4c60d6a44e3944307e7294b62e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c15a6a9393b247fabe85d43797a9f3c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e946f086cb4c41ba87979b71a8f84262": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f45792993e94d5c88712f435021f3ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8112629c0589459c82df02ea216c9018": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f8e8c2e7ee1452abdfbb835d502555f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bacb60b088546efb541abfd0a9733da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff51d5403b4c4e38a8f38601b1afa760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a38a97eb8c6146278c2794f9a802b531",
              "IPY_MODEL_ed80a1661b6b4ab09243250d962ebd4d",
              "IPY_MODEL_36c6a5d7d2c242769a64c5adc14b5da6"
            ],
            "layout": "IPY_MODEL_4d23103ea52c456c851747ffe3bb25fa"
          }
        },
        "a38a97eb8c6146278c2794f9a802b531": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f0aef3310714c3dbfcaf3f18b14bb5b",
            "placeholder": "",
            "style": "IPY_MODEL_9716b4dc9be640b0a417d1de01c30775",
            "value": "Filter:100%"
          }
        },
        "ed80a1661b6b4ab09243250d962ebd4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b569b8214934aa6bd9230311362e839",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1642f6e858d844b19f104c1bf44ec967",
            "value": 1000
          }
        },
        "36c6a5d7d2c242769a64c5adc14b5da6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb46e6833657484aadd3eae0c917aaf0",
            "placeholder": "",
            "style": "IPY_MODEL_fde77c0649d149988f81ee8be2a2e615",
            "value": "1000/1000[00:00&lt;00:00,22947.78examples/s]"
          }
        },
        "4d23103ea52c456c851747ffe3bb25fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f0aef3310714c3dbfcaf3f18b14bb5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9716b4dc9be640b0a417d1de01c30775": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b569b8214934aa6bd9230311362e839": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1642f6e858d844b19f104c1bf44ec967": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb46e6833657484aadd3eae0c917aaf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fde77c0649d149988f81ee8be2a2e615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee57312889904b9895b28569a2ae5e92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4c45a7760e84b56802cf6e92e75df2e",
              "IPY_MODEL_1f5f67bbd50d40a4af498f6ec9f5f750",
              "IPY_MODEL_91a266f0eb5d439d8e1c01f63194bd39"
            ],
            "layout": "IPY_MODEL_0ea77d24d7ff49c990c25d7ba8fad193"
          }
        },
        "a4c45a7760e84b56802cf6e92e75df2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4088c52969bc4596ba2ab2f9c798c2cc",
            "placeholder": "",
            "style": "IPY_MODEL_b1ac4461e5e244dc9faf6d25b0e42462",
            "value": "Map:100%"
          }
        },
        "1f5f67bbd50d40a4af498f6ec9f5f750": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4eebff02efec4dd9a5778f424864be4c",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ce30c9a21274e008ea2b7a18b8e47d8",
            "value": 1000
          }
        },
        "91a266f0eb5d439d8e1c01f63194bd39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8fec26aee854fdd87074679b249c932",
            "placeholder": "",
            "style": "IPY_MODEL_4dfcde6e63d54f62a95763a55d640408",
            "value": "1000/1000[00:00&lt;00:00,7539.62examples/s]"
          }
        },
        "0ea77d24d7ff49c990c25d7ba8fad193": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4088c52969bc4596ba2ab2f9c798c2cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1ac4461e5e244dc9faf6d25b0e42462": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4eebff02efec4dd9a5778f424864be4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ce30c9a21274e008ea2b7a18b8e47d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8fec26aee854fdd87074679b249c932": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dfcde6e63d54f62a95763a55d640408": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4bdc3041fa924382be9564b7050adff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46b4dd64e46147a0970315503528d2fa",
              "IPY_MODEL_88265476c2b948db890113e8c24ad419",
              "IPY_MODEL_1422590bb77e442bbc32b8393d997041"
            ],
            "layout": "IPY_MODEL_b03d811a3cb9427ca09092d56b1aa0cb"
          }
        },
        "46b4dd64e46147a0970315503528d2fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba29a0e0408e4ccdbb8f1086f2688dd3",
            "placeholder": "",
            "style": "IPY_MODEL_5364964182094a868638b735b838059e",
            "value": "Map:100%"
          }
        },
        "88265476c2b948db890113e8c24ad419": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72dc93bcd84c4a75baf4ad789edfd6c3",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_833e4c9402234555aa32a7da1efce69e",
            "value": 1000
          }
        },
        "1422590bb77e442bbc32b8393d997041": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbab3564b98740ebac79a4bbbcfa8e89",
            "placeholder": "",
            "style": "IPY_MODEL_2b8cc216305843048f3b4e6361947e93",
            "value": "1000/1000[00:00&lt;00:00,2732.43examples/s]"
          }
        },
        "b03d811a3cb9427ca09092d56b1aa0cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba29a0e0408e4ccdbb8f1086f2688dd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5364964182094a868638b735b838059e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72dc93bcd84c4a75baf4ad789edfd6c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "833e4c9402234555aa32a7da1efce69e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bbab3564b98740ebac79a4bbbcfa8e89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b8cc216305843048f3b4e6361947e93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "806612ba48d64423b5f7b57e07deb980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_80a2bc7658eb4827a31961eeb74b53bc",
              "IPY_MODEL_b94d4a9cd58743f58a4d906809d559ee",
              "IPY_MODEL_ea7dd1d64356456abc4dc28ab5bf6e51"
            ],
            "layout": "IPY_MODEL_099c7a8fcf8047598dc69cb56406f7bd"
          }
        },
        "80a2bc7658eb4827a31961eeb74b53bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6fdb9021d964411a1930c6b499868e7",
            "placeholder": "",
            "style": "IPY_MODEL_6c2a315cffb148aab52b9513ab40687a",
            "value": "Map:100%"
          }
        },
        "b94d4a9cd58743f58a4d906809d559ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4419339113c040f2ba3716bf64db0ee3",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d4e91b84e0b4f1e912832a4e4c42be1",
            "value": 1000
          }
        },
        "ea7dd1d64356456abc4dc28ab5bf6e51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d2c53f3d65749ea9bcd53497dcfed86",
            "placeholder": "",
            "style": "IPY_MODEL_8535288e565e452cbcb1aa156b5dd2e5",
            "value": "1000/1000[00:00&lt;00:00,2739.32examples/s]"
          }
        },
        "099c7a8fcf8047598dc69cb56406f7bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6fdb9021d964411a1930c6b499868e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c2a315cffb148aab52b9513ab40687a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4419339113c040f2ba3716bf64db0ee3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d4e91b84e0b4f1e912832a4e4c42be1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d2c53f3d65749ea9bcd53497dcfed86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8535288e565e452cbcb1aa156b5dd2e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}